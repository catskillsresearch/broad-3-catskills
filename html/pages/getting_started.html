<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Getting Started - Broad Institute IBD Challenge: Catskills Solution for Crunch 3</title>
    <link rel="stylesheet" href="../css/styles.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
</head>
<body>
    <header>
        <div class="logo-container">
            <h1>Broad Institute IBD Challenge: Catskills Solution for Crunch 3</h1>
        </div>
        <nav class="main-nav">
            <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="input_data.html">Input Data</a></li>
                <li><a href="data_structure.html">Data Structure</a></li>
                <li><a href="pipeline_flow.html">Pipeline Flow</a></li>
                <li><a href="process_flow.html">Process Flow</a></li>
                <li><a href="deepspot_architecture.html">DeepSpot Techniques</a></li>
                <li><a href="implementation.html">Implementation</a></li>
                <li><a href="visualizations.html">Visualizations</a></li>
                <li><a href="crunch_approaches.html">Integrated Approach</a></li>
                <li><a href="getting_started.html" class="active">Getting Started</a></li>
                <li><a href="hyperparameter_search.html">Hyperparameter Search</a></li>
            </ul>
        </nav>
        <button class="mobile-menu-toggle">
            <span></span>
            <span></span>
            <span></span>
        </button>
    </header>

    <div class="container">
        <aside class="sidebar">
            <div class="search-container">
                <input type="text" placeholder="Search documentation...">
                <button type="submit">Search</button>
            </div>
            <nav class="side-nav">
                <h3>On This Page</h3>
                <ul>
                    <li><a href="#installation">Installation</a></li>
                    <li><a href="#data-setup">Data Setup</a></li>
                    <li><a href="#small-dataset-pipeline">Small Dataset Pipeline</a></li>
                    <li><a href="#hyperparameter-search">Hyperparameter Search</a></li>
                    <li><a href="#full-pipeline">Full Pipeline</a></li>
                    <li><a href="#troubleshooting">Troubleshooting</a></li>
                </ul>
            </nav>
        </aside>

        <main class="content">
            <div class="breadcrumbs">
                <span><a href="../index.html">Home</a></span>
                <span>Getting Started</span>
            </div>

            <section id="installation">
                <h2>Installation</h2>
                <p>This section guides you through setting up the environment and installing the required dependencies for the Catskills Solution.</p>
                
                <h3>Requirements</h3>
                <p>The solution requires the following:</p>
                <ul>
                    <li>Python 3.8 or higher</li>
                    <li>CUDA-compatible GPU (recommended for full dataset)</li>
                    <li>At least 16GB RAM (32GB recommended for full dataset)</li>
                    <li>At least 100GB disk space for the full dataset and outputs</li>
                </ul>
                
                <h3>Environment Setup</h3>
                <p>We recommend using a virtual environment:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Setting Up Environment</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
# Clone the repository
git clone https://github.com/catskills/ibd-challenge-crunch3.git
cd ibd-challenge-crunch3

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
                    </code></pre>
                </div>
                
                <h3>Weights & Biases Setup</h3>
                <p>Our solution uses Weights & Biases for hyperparameter optimization and experiment tracking. You'll need to set up an account and log in:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Weights & Biases Setup</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
# Install wandb if not already installed
pip install wandb

# Log in to wandb
wandb login
                    </code></pre>
                </div>
                
                <p>Follow the prompts to complete the login process. You'll need to create an account at <a href="https://wandb.ai" target="_blank">wandb.ai</a> if you don't already have one.</p>
            </section>

            <section id="data-setup">
                <h2>Data Setup</h2>
                <p>Before running the pipeline, you need to prepare the data in the streamlined structure.</p>
                
                <h3>Data Preparation</h3>
                <p>Run the data preparation script to organize the raw data into the streamlined structure:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Data Preparation</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
python scripts/run_pipeline.py --config config/config.yaml --step data
                    </code></pre>
                </div>
                
                <p>This script will:</p>
                <ul>
                    <li>Create the streamlined data structure as described in the <a href="data_structure.html">Data Structure</a> page</li>
                    <li>Remove unused data elements (like unregistered images)</li>
                    <li>Organize the data by type (images, spatial, scRNA-seq, annotations)</li>
                    <li>Create the necessary directories for pipeline outputs</li>
                </ul>
                
                <div class="info-box">
                    <h3>Data Structure Verification</h3>
                    <p>After running the data preparation script, verify that the data structure matches the expected structure:</p>
                    <pre><code class="plaintext">
output/
└── data
    └── small_dataset
        ├── cell_coordinates.npy
        ├── config.yaml
        ├── gene_expression.npy
        ├── gene_names.npy
        ├── metadata.yaml
        ├── original_indices.npy
        ├── quality_scores.npy
        ├── region_labels.npy
        ├── test_indices.npy
        ├── train_indices.npy
        └── val_indices.npy
                    </code></pre>
                    <p>If any files are missing or directories are empty, check the logs for errors.</p>
                </div>
            </section>

            <section id="small-dataset-pipeline">
                <h2>Small Dataset Pipeline</h2>
                <p>We strongly recommend starting with the small dataset pipeline to validate the approach and optimize hyperparameters before scaling to the full dataset.</p>
                
                <h3>Creating the Small Dataset</h3>
                <p>Create a small subset of the data for rapid experimentation:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Creating Small Dataset</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
python scripts/create_small_dataset.py --config config/config.yaml --output_dir output/data/small_dataset --seed 42
                    </code></pre>
                </div>
                
                <p>You can adjust the parameters in the config file to control the size of the small dataset.</p>
                
                <p>A smaller dataset will run faster but may not capture all the complexity of the full dataset. We recommend starting with the default values and adjusting as needed.</p>
                
                <h3>Running the Small Dataset Pipeline</h3>
                <p>To run the complete pipeline on the small dataset:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Running Small Dataset Pipeline</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
python scripts/run_pipeline.py --config config/config.yaml --small_dataset
                    </code></pre>
                </div>
                
                <p>This will run the entire pipeline on the small dataset, including:</p>
                <ol>
                    <li>Feature extraction from the small dataset images</li>
                    <li>Hyperparameter search on the small dataset</li>
                    <li>Model training with the optimal hyperparameters</li>
                    <li>Gene expression prediction</li>
                    <li>Gene ranking</li>
                </ol>
                
                <p>The results will be saved in the <code>output/</code> directory structure as shown above.</p>
            </section>

            <section id="hyperparameter-search">
                <h2>Hyperparameter Search</h2>
                <p>The hyperparameter search is a critical component of our approach, allowing us to find the optimal model configuration.</p>
                
                <h3>Basic Hyperparameter Search</h3>
                <p>To run the hyperparameter search on the small dataset:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Running Hyperparameter Search on Small Dataset</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
python scripts/run_hyperparameter_search.py --config config/hyperparameter_search.yaml --small_dataset
                    </code></pre>
                </div>
                
                <p>This will perform a Bayesian optimization search to find the optimal hyperparameters for the model.</p>
                
                <div class="info-box">
                    <h3>Detailed Hyperparameter Search Documentation</h3>
                    <p>For comprehensive information about hyperparameter search, including:</p>
                    <ul>
                        <li>All available command-line options</li>
                        <li>Detailed explanation of search parameters</li>
                        <li>Advanced usage with different random seeds</li>
                        <li>Analyzing results in the W&B dashboard</li>
                        <li>Troubleshooting common issues</li>
                    </ul>
                    <p>Please refer to our dedicated <a href="hyperparameter_search.html">Hyperparameter Search</a> documentation page.</p>
                </div>
                
                <p>The optimal hyperparameters will be automatically saved to <code>output/features/hyperparameters/optimal_params.json</code> for use in the full pipeline.</p>
            </section>

            <section id="full-pipeline">
                <h2>Full Pipeline</h2>
                <p>Once you've verified that the small dataset pipeline is working correctly and found optimal hyperparameters, you can run the full pipeline on the complete dataset.</p>
                
                <h3>Running Hyperparameter Search on Full Dataset</h3>
                <p>If desired, you can refine the hyperparameters on the full dataset, starting from the optimal parameters found on the small dataset:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Running Hyperparameter Search on Full Dataset</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
python scripts/run_hyperparameter_search.py --config config/hyperparameter_search.yaml
                    </code></pre>
                </div>
                
                <p>This will perform a more focused search around the optimal parameters found on the small dataset. See the <a href="hyperparameter_search.html#full-dataset">Hyperparameter Search documentation</a> for more details.</p>
                
                <h3>Running the Full Pipeline</h3>
                <p>To run the complete pipeline on the full dataset:</p>
                
                <div class="code-container">
                    <div class="code-header">
                        <span>Running Full Pipeline</span>
                        <button class="copy-button">Copy</button>
                    </div>
                    <pre><code class="bash">
python scripts/run_pipeline.py --config config/config.yaml
                    </code></pre>
                </div>
                
                <p>This will run the entire pipeline on the full dataset, using the optimal hyperparameters found during the hyperparameter search.</p>
                
                <div class="warning-box">
                    <h3>Warning: Resource Requirements</h3>
                    <p>Running the full pipeline on the complete dataset requires significant computational resources:</p>
                    <ul>
                        <li>At least 32GB RAM</li>
                        <li>CUDA-compatible GPU with at least 8GB VRAM</li>
                        <li>Several hours of computation time</li>
                    </ul>
                    <p>Consider running on a machine with adequate resources or using cloud computing.</p>
                </div>
            </section>

            <section id="troubleshooting">
                <h2>Troubleshooting</h2>
                <p>This section provides solutions to common issues that may arise when running the pipeline.</p>
                
                <h3>Common Issues</h3>
                
                <div class="accordion">
                    <div class="accordion-item">
                        <div class="accordion-header">
                            <h4>Out of Memory Errors</h4>
                            <span class="accordion-icon">+</span>
                        </div>
                        <div class="accordion-content">
                            <p>If you encounter out of memory errors, try the following:</p>
                            <ul>
                                <li>Reduce the batch size in the configuration file</li>
                                <li>Use a smaller subset of the data</li>
                                <li>Run on a machine with more RAM or GPU memory</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div class="accordion-item">
                        <div class="accordion-header">
                            <h4>Missing Dependencies</h4>
                            <span class="accordion-icon">+</span>
                        </div>
                        <div class="accordion-content">
                            <p>If you encounter missing dependency errors, ensure that you've installed all required packages:</p>
                            <pre><code class="bash">
pip install -r requirements.txt
                            </code></pre>
                            <p>If you're still encountering issues, try installing the specific missing package:</p>
                            <pre><code class="bash">
pip install package_name
                            </code></pre>
                        </div>
                    </div>
                    
                    <div class="accordion-item">
                        <div class="accordion-header">
                            <h4>CUDA Errors</h4>
                            <span class="accordion-icon">+</span>
                        </div>
                        <div class="accordion-content">
                            <p>If you encounter CUDA errors, ensure that:</p>
                            <ul>
                                <li>You have a CUDA-compatible GPU</li>
                                <li>You have installed the correct version of CUDA for your GPU</li>
                                <li>You have installed the correct version of PyTorch for your CUDA version</li>
                            </ul>
                            <p>You can check your CUDA version with:</p>
                            <pre><code class="bash">
nvcc --version
                            </code></pre>
                            <p>And install the appropriate version of PyTorch from the <a href="https://pytorch.org/get-started/locally/" target="_blank">PyTorch website</a>.</p>
                        </div>
                    </div>
                    
                    <div class="accordion-item">
                        <div class="accordion-header">
                            <h4>Data Loading Errors</h4>
                            <span class="accordion-icon">+</span>
                        </div>
                        <div class="accordion-content">
                            <p>If you encounter errors loading the data, ensure that:</p>
                            <ul>
                                <li>The data paths in the configuration file are correct</li>
                                <li>The data files exist and are not corrupted</li>
                                <li>You have sufficient disk space</li>
                            </ul>
                            <p>You can check the data paths in the configuration file:</p>
                            <pre><code class="bash">
cat config/config.yaml
                            </code></pre>
                        </div>
                    </div>
                </div>
                
                <p>For more specific troubleshooting related to hyperparameter search, please refer to the <a href="hyperparameter_search.html#troubleshooting">Hyperparameter Search Troubleshooting</a> section.</p>
            </section>
        </main>
    </div>

    <footer>
        <div class="footer-content">
            <p>&copy; 2025 Catskills Research. All rights reserved.</p>
            <p>Broad Institute IBD Challenge: Catskills Solution for Crunch 3</p>
        </div>
    </footer>

    <script src="../js/scripts.js"></script>
    <script>hljs.highlightAll();</script>
    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'neutral',
            securityLevel: 'loose'
        });
    </script>
</body>
</html>
